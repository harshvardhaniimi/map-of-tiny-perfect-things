---
title: "01_Data Wrangling and Google Maps"
author: "Harshvardhan"
format: html
editor: visual
---

## Purpose

This notebook reads in all tables from the Google Sheet we have. The list of sheets will be provided as a vector.

## Loading Packages

First step is to load the packages.

```{r}
setwd("/Users/harshvardhan/Documents/Useful-Files/Misc/Map of Tiny Perfect Things/map-of-tiny-perfect-things/")
```

```{r}
# install and load necessary packages
# install.packages(c("googledrive", "googlesheets4"))
library(googledrive)
library(googlesheets4)
library(tidyverse)
```

Authenticating with Google Sheets:

```{r}
# set your googledrive token
# Note: You'll have to authenticate your session the first time you use this
# Simply run the following function and follow the instructions
# drive_auth()
```

## Getting the sheet

```{r}
# define the URL of your Google Sheet
url = "https://docs.google.com/spreadsheets/d/1UC2EvXsafSjDkNNZSnC8eB_FPwyy1KenFfhUveoKEoc/edit#gid=1196848595"
```

```{r}
# get the ID of the Google Sheet from the URL
# capturing the sheet id to use with drive_get()
sheet_id = sub(".*/d/(.*)/.*", "\\1", url)

# get info about the Google Sheet
sheet_info = drive_get(id = sheet_id)

sheet_info
```

## Reading each sheet

Define the sheets to read

```{r}
sheet_names = c("Dea - Bay Area", "Dea - NYC + DC + NJ", "Dea - PNW", "Dea - Vegas", "Harsh - Knoxville", "Harsh - PNW") 
```

Different sheets have different columns. Dea and mine's data collection strategies are slightly different. Thus, I will only keep Name, Type (Coffee, Food), Creator's Rec, Notes as the columns. Then based on what is the sheet's name, add that as a column as well.

```{r}
read_select_cols = function(url, 
                            sheet_name, 
                            cols_to_keep = c("name", "type", "location", 
                                             "creators_rec", "notes")) 
   {
   # Read the sheet into a data frame
   df = read_sheet(url, range = sheet_name) %>% 
      # clean names
      janitor::clean_names() %>% 
      # Select the desired columns
      select(all_of(cols_to_keep)) %>% 
      # Add a new column with the sheet name
      mutate(sheet_name = sheet_name)
  
   return(df)
}
```

Initialize an empty data frame to hold the combined data

```{r}
master_data = tibble()
```

Reading the sheets

```{r}
# Loop through each sheet name
for (sheet_name in sheet_names) {
  # Read the sheet and select the useful columns
  df = read_select_cols(url, sheet_name)
  
  # If the combined data frame is empty, then this is the first sheet, so replace the combined data frame with the data from this sheet
  if (nrow(master_data) == 0) {
    master_data = df
  } 
  # Otherwise, bind the new data to the existing data frame
  else {
    master_data = rbind(master_data, df)
  }
}
```

Here's how the master data looks like:

```{r}
master_data
```

## Data Processing

First, the sheet_name must be changed appropriately to reflect the place where it's at. It is required to get the Google Maps link/details as we would likely need more than just name.

```{r}
unique(master_data$sheet_name)
```

Let's refactor the code for getting the area. It will be used for searching the place. (This is not needed as it isn't useful. Should get city from location.)

```{r}
# Recode the sheet_name column to get area
#master_data = master_data %>% 
#   mutate(area = recode(sheet_name,
#                              "Dea - Bay Area" = "San Francisco Bay Area",
#                              "Dea - NYC + DC + NJ" = "New York; New Jersey; #Washington DC",
#                              "Dea - PNW" = "Portland, OR; Vancouver, WA",
#                              "Dea - Vegas" = "Las Vegas",
#                              "Harsh - Knoxville" = "Knoxville, TN",
#                              "Harsh - PNW" = "Portland, OR; Vancouver, WA"))
#master_data
```

Refactoring the type to few recognisable places.

```{r}
unique(master_data$type)
```

```{r}
# Recode the type column
# Recode the type column
master_data = master_data %>% 
   mutate(type = recode(
      type,
      "Coffee" = "Coffee",
      "Restaurant" = "Restaurant",
      "Pizza Shop" = "Pizza",
      "Food Truck" = "Food Truck",
      "Bagel Shop" = "Bagel",
      "Ice Cream Shop" = "Ice-cream",
      "Food Kiosk" = "Food Truck",
      "Bar" = "Bar",
      "Dessert Kiosk" = "Desert Kiosk",
      "Cafe" = "Cafe",
      "Cafe / Restaurant" = "Restaurant",
      "Cafe / Furniture" = "Cafe",
      "Cafe / Plants Store" = "Cafe",
      "Tea and Spices" = "Tea and Spices",
      "Bakery" = "Bakery",
      "Vietnamese" = "Restaurant",
      "Indian" = "Restaurant",
      "Pizza" = "Pizza",
      "Tea and Spices" = "Tea and Spices",
      "Food" = "Restaurant"
   )
)
master_data
```

To do:

1.  Change unique values of creators_rec from NA to No?
2.  Fill in all notes, including all places.

### Saving to a CSV File

```{r}
# found this weird text editor thing that excel does which is not ascii -- why microsoft, why?
master_data = master_data %>% 
   mutate(across(everything(), ~gsub("’|‘", "'", .)))

master_data %>% 
   write_csv(file = "master_data.csv", na = "")
```

## Getting Google Maps API working

```{r}
library(httr)
library(jsonlite)
library(purrr)
```

```{r}
# API key function
read_api_key = function(file_path) {
   # returning the first line of the text file at the file_path
   return(readLines(file_path)[1])
}
```

```{r}
# API Key (Harsh's API Key)
api_key = read_api_key("google_places_api_key.txt")

# load googleway
library(googleway)
set_key(key = api_key)
```

Function to get information from Google Maps, given place name and area.

```{r}
get_place_info = function(place_name, area) {
  if (is.na(area)){
    print(paste0("Area name not provided for place ", place_name))
    return(
      tibble(
        name = place_name,
        address = NA,
        rating = NA,
        user_ratings_total = NA,
        google_maps_link = NA,
        lat = NA,
        lng = NA
      ))
  }

  # Construct the search query
  query = paste0(place_name, " ", area)

  # Perform a Google Places search
  result_search = google_places(search_string = query)

  if (length(result_search$results) == 0) {
    print(paste0("Couldn't find place ", place_name, " in ", area))
    
    return(
      tibble(
        name = place_name,
        address = NA,
        rating = NA,
        user_ratings_total = NA,
        google_maps_link = NA,
        lat = NA,
        lng = NA
      )
    )
  } else {
    # Extract the information
     print(paste0("Working on ", place_name, " ", area))
     result_details = result_search$results[1,]
     place_id = result_details$place_id
    address = result_details$formatted_address
    rating = result_details$rating
    user_ratings_total = result_details$user_ratings_total
    google_maps_link = paste0("https://www.google.com/maps/search/?api=1&query=", URLencode(address), "&query_place_id=", place_id)
    lat = result_details$geometry$location$lat
    lng = result_details$geometry$location$lng

    return(
      tibble(
        name = place_name,
        address = address,
        rating = rating,
        user_ratings_total = user_ratings_total,
        google_maps_link = google_maps_link,
        lat = lat,
        lng = lng
      )
    )
  }
}
```

```{r}
# Apply the function to each row of your data frame
places_info = master_data %>%
  split(1:nrow(.)) %>%
  map_dfr(~ get_place_info(.$name, .$location))

places_info
```

```{r}
# Merge with the original data frame
master_data = left_join(master_data, places_info, by = "name")
master_data
```

```{r}
# save to CSV
master_data %>% 
   write_csv(file = "master_data_google_details.csv",
             na = "")
```
